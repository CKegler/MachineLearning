plot(binom_Zero7_mids, binom_Zero7_intensities,  type="b",xlim=c(1,60), col="orange",main="Binomial Distributions for Trials = 60, p=0.3, 0.5 ,0.7", ylab="Counts")
lines( binom_Zero3_mids, binom_Zero3_intensities , type="b", col="red")
lines(binom_Zero5_mids, binom_Zero5_intensities,  type="b", col="blue")
legend( locator(1), legend=tlegend, border="black", horiz=FALSE, title="Legend For Plot Lines")
#Generate the line plots to show binomial distribution from additional vectors
tlegend = c("Red = (p=0.3)", "Blue = (p=0.5)", "Orange = (p=0.7)")
plot(binom_Zero7_mids, binom_Zero7_intensities,  type="b",xlim=c(1,60), col="orange",main="Binomial Distributions for Trials = 60, p=0.3, 0.5 ,0.7", ylab="Frequency")
lines( binom_Zero3_mids, binom_Zero3_intensities , type="b", col="red")
lines( binom_Zero5_mids, binom_Zero5_intensities,  type="b", col="blue")
legend( locator(1), legend=tlegend, border="black", horiz=FALSE, title="Legend For Plot Lines")
tlegend = c("Red = (p=0.3)", "Blue = (p=0.5)", "Orange = (p=0.7)")
plot(binom_Zero7_mids, binom_Zero7_intensities,  type="b",xlim=c(1,60), col="orange",main="Binomial Distributions for Trials = 60, p=0.3, 0.5 ,0.7",xlab="k-value" ylab="Frequency")
lines( binom_Zero3_mids, binom_Zero3_intensities , type="b", col="red")
lines( binom_Zero5_mids, binom_Zero5_intensities,  type="b", col="blue")
legend( locator(1), legend=tlegend, border="black", horiz=FALSE, title="Legend For Plot Lines")
#Generate the line plots to show binomial distribution from additional vectors
tlegend = c("Red = (p=0.3)", "Blue = (p=0.5)", "Orange = (p=0.7)")
plot(binom_Zero7_mids, binom_Zero7_intensities,  type="b",xlim=c(1,60), col="orange",main="Binomial Distributions for Trials = 60, p=0.3, 0.5 ,0.7",xlab="k-value" ylab="Frequency")
lines( binom_Zero3_mids, binom_Zero3_intensities , type="b", col="red")
lines( binom_Zero5_mids, binom_Zero5_intensities,  type="b", col="blue")
legend( locator(1), legend=tlegend, border="black", horiz=FALSE, title="Legend For Plot Lines")
tlegend = c("Red = (p=0.3)", "Blue = (p=0.5)", "Orange = (p=0.7)")
plot(binom_Zero7_mids, binom_Zero7_intensities,  type="b",xlim=c(1,60), col="orange",main="Binomial Distributions for Trials = 60, p=0.3, 0.5 ,0.7",xlab="k-value" ylab="Frequency")
lines( binom_Zero3_mids, binom_Zero3_intensities , type="b", col="red")
lines( binom_Zero5_mids, binom_Zero5_intensities,  type="b", col="blue")
legend( locator(1), legend=tlegend, border="black", horiz=FALSE, title="Legend For Plot Lines")
tlegend = c("Red = (p=0.3)", "Blue = (p=0.5)", "Orange = (p=0.7)")
plot(binom_Zero7_mids, binom_Zero7_intensities,  type="b",xlim=c(1,60), col="orange",main="Binomial Distributions for Trials = 60, p=0.3, 0.5 ,0.7",xlab="k-value" ylab="Frequency")
lines( binom_Zero3_mids, binom_Zero3_intensities , type="b", col="red")
lines( binom_Zero5_mids, binom_Zero5_intensities,  type="b", col="blue")
#Generate the line plots to show binomial distribution from additional vectors
tlegend = c("Red = (p=0.3)", "Blue = (p=0.5)", "Orange = (p=0.7)")
plot(binom_Zero7_mids, binom_Zero7_intensities,  type="b",xlim=c(1,60), col="orange",main="Binomial Distributions for Trials = 60, p=0.3, 0.5 ,0.7",xlab="k-value", ylab="Frequency")
lines( binom_Zero3_mids, binom_Zero3_intensities , type="b", col="red")
lines( binom_Zero5_mids, binom_Zero5_intensities,  type="b", col="blue")
legend( locator(1), legend=tlegend, border="black", horiz=FALSE, title="Legend For Plot Lines")
head(faithful(
;
head(faithful);
save.image("C:\\CSCIE185\\hw2\\e162hw2\\e162_KeglerColin_hw2.RData")
size(faithful)
library(faithful);
describe(faithful);
duration = faithful$eruptions;
waiting = faithful$waiting;
head(cbind(duration, waiting));
breaksDur = seq(0.5, 6.0, by 0.5)
breaksDur = seq(0.5, 6.0, by 0.5);
breaksDur = seq(0.5, 6.0, by=0.5);
breaksWaiting = seq(10, 100, by=10);
duration.cut = cut(duration, breaksDur, right=FALSE);
waiting.cut = cut(waiting, breaksWaiting, right=FALSE);
duration.freq = table(duration.cut);
duration.freq
waiting.freq = table(waiting.cut);
waiting.freq
max(waiting)
save.image("C:\\CSCIE185\\hw2\\e162hw2\\e162_KeglerColin_hw2.RData")
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(datasets)
data(airquality)
p <- xyplot(Ozone ~ Wind | factor(Month), data = airquality)
library(ggplot2)
intall.package("ggplot2")
intall.packages("ggplot2")
install.packages("ggplot2")
g <- ggplot(movies, aes(votes, rating))
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
library(datasets)
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
g <- ggplot(movies, aes(votes, rating))
print(g)
load("C:/RWorkspace/Cousera/CleaningData/.RData")
library(xlsx)
install.packages(c("boot", "class", "cluster", "codetools", "foreign", "jsonlite", "KernSmooth", "lattice", "manipulate", "MASS", "Matrix", "mgcv", "mime", "nlme", "nnet", "plyr", "Rcpp", "RCurl", "rpart", "spatial", "stringr", "survival", "testthat"))
install.packages("xlsx")
library(xlsx)
install.packages("rJava")
library(xlsx)
r --version
?version
R.Version()
swirl()
swirl()
swirl
load("C:/RWorkspace/Cousera/RegressionModels/.RData")
swirl()
library(swirl)
swirl()
lm(child ~ parent, galton)
fit <- lm(child ~ parent, galton)
summary(fit)
fit$residuals
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
rhs - lhs
lhs - rhs
all.equal(lhs, rhs)
View(galton)
varchild <- var(galton$child)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- est(fit)
varEst <- est(ols.ic, ols.slope)
varEst <- est( ols.slope, ols.ic)
varEst <- var( est( ols.slope, ols.ic))
all.equal (varChild, sum(varRes + varEst))
all.equal (varChild, varRes + varEst)
efit <- lm(accel ~ mag+dist, attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
library(swirl)
swirl()
cor(gpa_nor, gch_nor)
l_nor <- lm(gch_nor ~ gpa_nor)
library(swirl)
swirl()
ones <- rep(1, nrow(galton))
lm(child ~ ones + parent -1, galton)
lm(child ~ parent, galton)
lm(child ~ 1, galton)
view(trees)
head(trees)
fit <- lm(Volume ~ Girth + Height + Constant -1, trees)
trees2 <- eliminate("Girth", trees)
head(trees2)
fit2  <- lm(Volume ~ Height + Constant -1, trees2)
lapply(list(fit, fit2), coef)
library(UsingR);
require(GGally);
require(ggplot2);
require(VIF);
data(mtcars);
fit <- lm(mpg ~ ., data = mtcars)
fit_no_intercept <- lm(mpg ~ . - 1, data = mtcars)
#1 Do pairwise ggplot of the regressors without an intercept
g = ggpairs(fit_no_intercept, lower = list(continuous = "smooth"),params = c(method = "loess"))
g
library(UsingR);
require(GGally);
require(ggplot2);
require(VIF);
data(mtcars);
fit <- lm(mpg ~ ., data = mtcars)
fit_no_intercept <- lm(mpg ~ . - 1, data = mtcars)
#1 Do pairwise ggplot of the regressors without an intercept
g = ggpairs(fit_no_intercept, lower = list(continuous = "smooth"),params = c(method = "loess"))
g
g = ggpairs(fit_no_intercept, lower = list(continuous = "smooth"),params = c(method = "loess"))
g
library(UsingR);
require(GGally);
require(ggplot2);
require(VIF);
data(mtcars);
g = ggpairs(fit_no_intercept, lower = list(continuous = "smooth"),params = c(method = "loess"))
g
g = ggpairs(fit_no_intercept, lower = list(continuous = "smooth"),params = c(method = "loess"))
g
#1 Do pairwise ggplot of the regressors without an intercept
g = ggpairs(fit_no_intercept, lower = list(continuous = "smooth"),params = c(method = "loess"))
g
data(mtcars);
fit <- lm(mpg ~ ., data = mtcars)
fit_no_intercept <- lm(mpg ~ . - 1, data = mtcars)
#1 Do pairwise ggplot of the regressors without an intercept
g = ggpairs(fit_no_intercept, lower = list(continuous = "smooth"),params = c(method = "loess"))
g
# Plot Mpg vs Weight, distinguishing Automatic from Manual Transmission
g_wt = ggplot(mtcars, aes(x = wt, y = mpg, colour = factor(am)))
g_wt = g_wt + geom_point(size = 6, colour = "black") + geom_point(size = 4)
g_wt = g_wt + scale_color_discrete(name="Transmission\nType",
breaks=c("0", "1"),
labels=c("Automatic", "Manual")
)
g_wt = g_wt + xlab("Weight (lb/1000)") + ylab("Miles per Gallon")
g_wt = g_wt + ggtitle("Mpg vs. Weight\nby Transmission Type") +
theme(plot.title = element_text(lineheight=.8, face="bold"))
g_wt
# Plot Mpg vs qsec, distinguishing Automatic from Manual Transmission
g_qsec = ggplot(mtcars, aes(x = wt, y = mpg, colour = factor(am)))
g_qsec = g_qsec + geom_point(size = 6, colour = "black") + geom_point(size = 4)
g_qsec = g_qsec + scale_color_discrete(name="Transmission\nType",
breaks=c("0", "1"),
labels=c("Automatic", "Manual")
)
g_qsec = g_qsec + xlab("Time (sec) for 1/4 Mile") + ylab("Miles per Gallon")
g_qsec = g_qsec +  ggtitle("Mpg vs. Qsec Time\nby Transmission Type") +
theme(plot.title = element_text(lineheight=.8, face="bold"))
g_qsec
# Do a box plot to explore difference between manual vs. automatic transmission
boxplot(mpg~am, data = mtcars,
col = c("dark grey", "light grey"),
xlab = "Transmission",
ylab = "Miles per Gallon",
main = "MPG by Transmission Type")
boxplot(mpg~am, data = mtcars,
col = c("dark grey", "light grey"),
xlab = "Transmission (Automtic=0, Manual=1",
ylab = "Miles per Gallon",
main = "MPG by Transmission Type")
legend("bottomright", inset=.05, title="Tranmission Type",
c("Automatic","Manual"), fill=terrain.colors(2), horiz=FALSE)
boxplot(mpg~am, data = mtcars,
col = c("dark grey", "light grey"),
xlab = "Transmission",
ylab = "Miles per Gallon",
main = "MPG by Transmission Type")
legend("bottomright", inset=.05, title="Tranmission Type",
c("Automatic","Manual"), fill=c("dark grey", "light grey"), horiz=FALSE)
boxplot(mpg~am, data = mtcars,
col = c("dark grey", "light grey"),
xlab = "Transmission",
ylab = "Miles per Gallon",
main = "MPG by Transmission Type")
legend("bottom", inset=.05, title="Tranmission Type",
c("Automatic","Manual"), fill=c("dark grey", "light grey"), horiz=FALSE)
boxplot(mpg~am, data = mtcars,
col = c("dark grey", "light grey"),
xlab = "Transmission",
ylab = "Miles per Gallon",
main = "MPG by Transmission Type")
legend("upperleft", inset=.05, title="Tranmission Type",
c("Automatic","Manual"), fill=c("dark grey", "light grey"), horiz=FALSE)
boxplot(mpg~am, data = mtcars,
col = c("dark grey", "light grey"),
xlab = "Transmission",
ylab = "Miles per Gallon",
main = "MPG by Transmission Type")
legend("topleft", inset=.05, title="Tranmission Type",
c("Automatic","Manual"), fill=c("dark grey", "light grey"), horiz=FALSE)
automaticTransmission <- mtcars[mtcars$am == "0",]
manualTransmission    <- mtcars[mtcars$am == "1",]
t.testresults <- t.test(automaticTransmission$mpg, manualTransmission$mpg)
t.testresults
# View Residuals
par(mfrow = c(2, 2))
plot(fit_no_intercept)
plot(predict(fit_no_intercept), resid(fit_no_intercept), pch = '.')
par(mfrow = c(2, 2))
plot(fit_no_intercept)
plot(predict(fit_no_intercept), resid(fit_no_intercept), pch = '.')
plot(predict(fit_no_intercept), resid(fit_no_intercept), pch = '*')
plot(predict(fit_no_intercept), resid(fit_no_intercept), pch = '*')
install.packages("knitr")
save.image("C:/RWorkspace/Cousera/RegressionModels/project/RegressionProjectWS.RData")
summary(fit_no_intercept)
setwd("C:/RWorkspace/Cousera/MachineLearning/project")
source("KeglerMLProject"")
;
q
;
""
source("KeglerMLProject")
source("KeglerMLProject.R")
dim(pmlTrainingData)
?read.csv
source("KeglerMLProject.R")
nsv <- nearZeroVar(pmlTrainingData,saveMetrics=TRUE)
nsv
colNames(nsv[nzv==FALSE])
colnames(nsv[nzv==FALSE])
nsv[nsv$nzv==FALSE])
colnames(nsv[nsv$nzv==FALSE])
library(caret);
library(ggplot2);
pmlTrainingData = read.csv("pml-training.csv", header=TRUE, na.strings="NA")  # read csv file
#Detect columns with near zero variance, as candidates to discard from training model
nsv <- nearZeroVar(pmlTrainingData,saveMetrics=TRUE)
library(caret);
library(ggplot2);
omitValues <- c("NA", "#DIV/0!")
# read csv file
pmlTrainingData = read.csv("pml-training.csv", header=TRUE, na.strings="NA", stringsAsFactors=FALSE)
#Detect columns with near zero variance, as candidates to discard from training model
nsv <- nearZeroVar(pmlTrainingData,saveMetrics=TRUE)
View(nsv)
nsv[nzv==TRUE]
nsv[nsv$nzv==TRUE]
colnames(nsv$nzv==TRUE)
row.names(nsv$nzv==TRUE)
nsv$nzv==TRUE
which(nsv, nsv$nzv==TRUE)
which(nsv$nzv==TRUE)
pmlTrainingData2  <-  pmlTrainingData[, which(nsv$nzv==FALSE)]
summary(pmlTrainingData2)
summarize(pmlTrainingData2)
summary(pmlTrainingData2)
describe(pmlTrainingData2)
summary(pmlTrainingData2)
summary(pmlTrainingData2)
library(caret);
library(ggplot2);
omitValues <- c("NA", "#DIV/0!")
# read csv file
pmlTrainingData = read.csv("pml-training.csv", header=TRUE, na.strings="NA", stringsAsFactors=FALSE)
#Detect columns with near zero variance, as candidates to discard from training model
nsv <- nearZeroVar(pmlTrainingData,saveMetrics=TRUE)
pmlTrainingData2  <-  pmlTrainingData[, which(nsv$nzv==FALSE)]
summary(pmlTrainingData2)
head(pmlTraiingData2)
head(pmlTrainingData2)
pmlTrainingData2$user_name  <-  as.factor(pmlTrainingData2$user_name)
head(as.POSIXlt(pmlTrainingData2$cvtd_timestamp) )
head(as.POSIXlt(pmlTrainingData2$cvtd_timestamp, format="%M/%d/%Y H:m") )
head(as.POSIXlt(pmlTrainingData2$cvtd_timestamp, format="%m/%d/%Y %h:%M") )
head(as.POSIXlt(pmlTrainingData2$cvtd_timestamp, format="%m/%d/%Y %H:%M") )
pmlTrainingData2$cvtd_timestamp <- as.POSIXlt(pmlTrainingData2$cvtd_timestamp, format="%m/%d/%Y %H:%M")
head(pmlTrainingData2)
pmlTrainingData2$classe  <-  as.factor(mlTrainingData2$classe)
pmlTrainingData2$classe  <-  as.factor(pmlTrainingData2$classe)
summary(pmlTrainingData2)
head(as.Date(as.POSIXlt(pmlTrainingData2$raw_timestamp_part_2)))
head(as.Date(as.POSIXlt(pmlTrainingData2$raw_timestamp_part_2, tz="")))
head(as.Date(as.POSIXlt(pmlTrainingData2$raw_timestamp_part_2, tz="", origin = "1970-01-01")))
head(as.Date(as.POSIXlt(pmlTrainingData2$raw_timestamp_part_2, tz="", origin = "2011-02-12")))
head(pmlTrainingData2[1..4])
head(pmlTrainingData2[1...4])
head(pmlTrainingData2[1:4])
head(pmlTrainingData2[1:5])
head(as.Date(as.POSIXlt(pmlTrainingData2$raw_timestamp_part_2, tz="", origin = "2011-02-12")))
library(caret);
library(ggplot2);
naValues <- c("NA", "#DIV/0!")
# read csv file
pmlTrainingData = read.csv("pml-training.csv", header=TRUE, na.strings=naValues, stringsAsFactors=FALSE)
#Detect columns with near zero variance, as candidates to discard from training model
nsv <- nearZeroVar(pmlTrainingData,saveMetrics=TRUE)
pmlTrainingData2  <-  pmlTrainingData[, which(nsv$nzv==FALSE)]
pmlTrainingData2$user_name  <-  as.factor(pmlTrainingData2$user_name)
pmlTrainingData2$cvtd_timestamp <- as.POSIXlt(pmlTrainingData2$cvtd_timestamp, format="%m/%d/%Y %H:%M") )
pmlTrainingData2$cvtd_timestamp <- as.POSIXlt(pmlTrainingData2$cvtd_timestamp, format="%m/%d/%Y %H:%M")
summary(pmlTrainingData2$raw_timestamp_part_1)
max(pmlTrainingData2$raw_timestamp_part_1) - min(pmlTrainingData2$raw_timestamp_part_1)
hist(pmlTrainingData2$raw_timestamp_part_1)
hist(pmlTrainingData2$raw_timestamp_part_1, bin=4)
?hist
hist(pmlTrainingData2$raw_timestamp_part_1, labels=true)
hist(pmlTrainingData2$raw_timestamp_part_1, labels=TRUE)
summary(pmlTrainingData2$raw_timestamp_part_2)
hist(pmlTrainingData2$raw_timestamp_part_2)
pmlTrainingData2$raw_timestamp_part_1  <- as.factor(pmlTrainingData2$raw_timestamp_part_1)
library(caret);
library(ggplot2);
naValues <- c("NA", "#DIV/0!")
# PART 1 (Data Input):read csv file
pmlTrainingData = read.csv("pml-training.csv", header=TRUE, na.strings=naValues, stringsAsFactors=FALSE)
# PART 2 (Cleaning Data)
#Detect columns with near zero variance, as candidates to discard from training model
nsv <- nearZeroVar(pmlTrainingData,saveMetrics=TRUE)
pmlTrainingData2  <-  pmlTrainingData[, which(nsv$nzv==FALSE)]
#convert user_name to factor variables
pmlTrainingData2$user_name  <-  as.factor(pmlTrainingData2$user_name)
#convert cvtd_timestamp to friendly date format
pmlTrainingData2$cvtd_timestamp <- as.POSIXlt(pmlTrainingData2$cvtd_timestamp, format="%m/%d/%Y %H:%M")
# Explore the variable, raw_timestamp_part_1
#  head(as.Date(as.POSIXlt(pmlTrainingData2$raw_timestamp_part_1, tz="", origin = "2011-02-12")))
#  hist(pmlTrainingData2$raw_timestamp_part_1, labels=TRUE)
#From the histogram of raw_timestamp_part_1 only has 4 values, which may correspond to each of the 4
#wearable devices - the belt, the arm band, the glove, and the dumbbell
summary(pmlTrainingData2$raw_timestamp_part_1)
cut(pmlTrainingData2$raw_timestamp_part_1, breaks=4)
cut(pmlTrainingData2$raw_timestamp_part_1, breaks=4, lables=1:4)
?cut
cut(pmlTrainingData2$raw_timestamp_part_1, breaks=4, lables=FALSE)
cut(pmlTrainingData2$raw_timestamp_part_1, breaks=4, labels=FALSE)
data.frame(pmlTrainingData2$raw_timestamp_part_1, bin=cut(dpmlTrainingData2$raw_timestamp_part_1,breaks=4, labels=FALSE))
data.frame(pmlTrainingData2$raw_timestamp_part_1, bin=cut(pmlTrainingData2$raw_timestamp_part_1,breaks=4, labels=FALSE))
head( data.frame(pmlTrainingData2$raw_timestamp_part_1, bin=cut(pmlTrainingData2$raw_timestamp_part_1,breaks=4, labels=FALSE)) )
pmlTrainingData2$raw_timestamp_part_1 <- data.frame(pmlTrainingData2$raw_timestamp_part_1, bin=cut(pmlTrainingData2$raw_timestamp_part_1,breaks=4, labels=FALSE))$bin
pmlTrainingData2$raw_timestamp_part_1 <- as.factor(pmlTrainingData2$raw_timestamp_part_1)
summary(pmlTrainingData2$raw_timestamp_part_2)
998800/1000
998800/60000
500700/60000
pmlTrainingData2$raw_timestamp_part_2 <- pmlTrainingData2$raw_timestamp_part_2 / 60000
summary(pmlTra)iningData2)
summary(pmlTrainingData2)
smallerTrainingDataCov  <- prcomp(pmlTrainingData2)
smallerTrainingDataCov  <- prcomp(pmlTrainingData[ -(classe)])
smallerTrainingDataCov  <- prcomp(pmlTrainingData[ -classe])
smallerTrainingDataCov  <- prcomp(pmlTrainingData[ -colnum(classe)])
smallerTrainingDataCov  <- prcomp(pmlTrainingData[ -which( colnames(pmlTrainingData)=="classe" )])
dim(pmlTrainingData2)
smallerTrainingDataCov  <- prcomp(pmlTrainingData[ ,-(1:5),-124])
smallerTrainingDataCov  <- prcomp(pmlTrainingData[ ,-(1:5)])
smallerTrainingDataCov  <- prcomp(pmlTrainingData[ ,(6:124)])
smallerTrainingDataCov  <- prcomp(pmlTrainingData[ ,(6:124)])
smallerTrainingDataCov  <- prcomp(pmlTrainingData[ ,(6:124)])
smallerTrainingDataCov  <- prcomp(pmlTrainingData[ ,(6:124)])
smallerTrainingDataCov  <- prcomp(pmlTrainingData2[ ,(6:124)])
smallerTrainingDataCov  <- prcomp(pmlTrainingData2[6:124])
View(pmlTrainingData2)
smallerTrainingDataCov  <- prcomp(pmlTrainingData2[6:124])
View(pmlTrainingData)
smallerTrainingDataCov  <- prcomp(pmlTrainingData2[,6:124])
smallerTrainingDataCov  <- prcomp(pmlTrainingData2[,6:124])
library(caret);
library(ggplot2);
naValues <- c("NA", "#DIV/0!")
# PART 1 (Data Input):read csv file
pmlTrainingData = read.csv("pml-training.csv", header=TRUE, na.strings=naValues, stringsAsFactors=FALSE)
# PART 2 ( Basic Preprocessing of Data)
#Detect columns with near zero variance, as candidates to discard from training model
nsv <- nearZeroVar(pmlTrainingData,saveMetrics=TRUE)
pmlTrainingData2  <-  pmlTrainingData[, which(nsv$nzv==FALSE)]
#convert user_name to factor variables
pmlTrainingData2$user_name  <-  as.factor(pmlTrainingData2$user_name)
#convert cvtd_timestamp to friendly date format
pmlTrainingData2$cvtd_timestamp <- as.POSIXlt(pmlTrainingData2$cvtd_timestamp, format="%m/%d/%Y %H:%M")
# Explore the variable, raw_timestamp_part_1
#  head(as.Date(as.POSIXlt(pmlTrainingData2$raw_timestamp_part_1, tz="", origin = "2011-02-12")))
#  hist(pmlTrainingData2$raw_timestamp_part_1, labels=TRUE)
# From the histogram of raw_timestamp_part_1 falls into 1 of 4 total bins,
# which may correspond to each of the 4 wearable devices -
# the belt, the arm band, the glove, and the dumbbell. So,
# convert pmlTrainingData2$raw_timestamp_part_1  values into one of the four bins
# as a factor variable
pmlTrainingData2$raw_timestamp_part_1 <- data.frame(pmlTrainingData2$raw_timestamp_part_1,
bin=cut(pmlTrainingData2$raw_timestamp_part_1,
breaks=4, labels=FALSE))$bin
pmlTrainingData2$raw_timestamp_part_2 <- pmlTrainingData2$raw_timestamp_part_2 / 60000
smallerTrainingDataCov  <- prcomp(pmlTrainingData2[6:124])
smallerTrainingDataCov  <- prcomp(pmlTrainingData2[,6:124])
smallerTrainingDataCov  <- prcomp(pmlTrainingData2[,6:123])
View(pmlTrainingData2)
View(pmlTrainingData2)
?write
write(pmlTrainingData , "pmlTrainingData.csv", sep=",")
write(pmlTrainingData2 , "pmlTrainingData2.csv", sep=",")
write(pmlTrainingData2 , file="pmlTrainingData2.csv", sep=",")
pmlTrainingData2
smallerTrainingDataCov  <- prcomp(pmlTrainingData2[,6:123])
write(as.frame(pmlTrainingData2) , file="pmlTrainingData2.csv", sep=",")
write.table(pmlTrainingData2 , file="pmlTrainingData2.csv", sep=",")
?read.csv
library(caret);
library(ggplot2);
naValues <- c("NA", "#DIV/0!")
# PART 1 (Data Input):read csv file
pmlTrainingData = read.csv("pml-training.csv", header=TRUE, na.strings=naValues, stringsAsFactors=FALSE, row.names=1)
# PART 2 ( Basic Preprocessing of Data)
#Detect columns with near zero variance, as candidates to discard from training model
nsv <- nearZeroVar(pmlTrainingData,saveMetrics=TRUE)
pmlTrainingData2  <-  pmlTrainingData[, which(nsv$nzv==FALSE)]
#convert user_name to factor variables
pmlTrainingData2$user_name  <-  as.factor(pmlTrainingData2$user_name)
#convert cvtd_timestamp to friendly date format
pmlTrainingData2$cvtd_timestamp <- as.POSIXlt(pmlTrainingData2$cvtd_timestamp, format="%m/%d/%Y %H:%M")
# Explore the variable, raw_timestamp_part_1
#  head(as.Date(as.POSIXlt(pmlTrainingData2$raw_timestamp_part_1, tz="", origin = "2011-02-12")))
#  hist(pmlTrainingData2$raw_timestamp_part_1, labels=TRUE)
# From the histogram of raw_timestamp_part_1 falls into 1 of 4 total bins,
# which may correspond to each of the 4 wearable devices -
# the belt, the arm band, the glove, and the dumbbell. So,
# convert pmlTrainingData2$raw_timestamp_part_1  values into one of the four bins
# as a factor variable
pmlTrainingData2$raw_timestamp_part_1 <- data.frame(pmlTrainingData2$raw_timestamp_part_1,
bin=cut(pmlTrainingData2$raw_timestamp_part_1,
breaks=4, labels=FALSE))$bin
head(pmlTrainingData2)
smallerTrainingDataCov  <- prcomp(pmlTrainingData2[,6:123])
?prcomp
pmlTrainingData3  <-  pmlTrainingData2[2:nrows(pmlTrainingData2) ,]
pmlTrainingData3  <-  pmlTrainingData2[2:nrow(pmlTrainingData2) ,]
smallerTrainingDataCov  <- prcomp(pmlTrainingData3[,6:123])
View(pmlTrainingData3)
?str
str(pmlTrainingData2)
pmlTrainingData3  <-  pmlTrainingData2[,6:123]
View(pmlTrainingData3)
summary(pmlTrainingData3)
pmlTrainingData3  <- pmlTrainingData3[-colnum(classe)]
pmlTrainingData3  <- pmlTrainingData3[which( pmlTrainingData3, -colnum(classe))]
pmlTrainingData3  <- pmlTrainingData3[which( pmlTrainingData3, -colname==(classe))]
pmlTrainingData3  <- pmlTrainingData3[, -which( pmlTrainingData3, colname=="classe")]
pmlTrainingData3  <- pmlTrainingData3[, -which(colnames(pmlTrainingData3)=="classe")]
smallerTrainingDataCov  <- prcomp(pmlTrainingData3[,6:123])
smallerTrainingDataCov  <- prcomp(pmlTrainingData3)
str(pmlTrainingData3)
View(pmlTrainingData3)
smallerTrainingDataCov  <- prcomp(pmlTrainingData3)
?prcomp
smallerTrainingDataCov  <- prcomp(pmlTrainingData3, na.omit=TRUE)
str(pmlTrainingData3)
summary(pmlTrainingData3)
smallerTrainingDataCov  <- prcomp(pmlTrainingData3, na.action=na.omit)
na.omit
?na.omit
pmlTrainingData3  <- pmlTrainingData3[, -which(colSums(is.na(pmlTrainingData3)) > 0)]
smallerTrainingDataCov  <- prcomp(pmlTrainingData3)
smallerTrainingDataCov$rotation[dimnames]
smallerTrainingDataCov$dimnames
smallerTrainingDataCov$rotation$dimnames
smallerTrainingDataCov$rotation
smallerTrainingDataCov$x
smallerTrainingDataCov  <- prcomp(pmlTrainingData3, scale=TRUE)
